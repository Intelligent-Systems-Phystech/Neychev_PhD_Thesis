{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoration of superposition matrices\n",
    "\n",
    "This notebook is using functions from `algorithms.py` and `utils.py`. Refer to `requirements.txt` to install the required packages. This code is tested in environment with python version available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.7 (default, May  7 2020, 21:25:33) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Intelligent-Systems-Phystech/Neychev_PhD_Thesis/main/SymbolicRegressionPaper/code/algorithms.py -nc\n",
    "!wget https://raw.githubusercontent.com/Intelligent-Systems-Phystech/Neychev_PhD_Thesis/main/SymbolicRegressionPaper/code/utils.py -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import add_noise_to_matrix, make_random_correct_adj_matrix, restore_matrix\n",
    "from utils import do_exp, do_exp_multiple, make_plot, make_plot_multiple, generate_arities_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check of the `generate_arities_list` function. The original (correct) and noised adjacency matrices are shown below. Noise level can be adjusted explicitly (and should take value from $[0, 1]$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(421)\n",
    "random.seed(a=472443)\n",
    "\n",
    "arities = generate_arities_list(3)\n",
    "var_number = 1\n",
    "print(arities)\n",
    "\n",
    "new_matrix = make_random_correct_adj_matrix(arities, var_number, complexity_limit=-1)\n",
    "\n",
    "print(new_matrix)\n",
    "\n",
    "noisy_matrix = add_noise_to_matrix(\n",
    "    new_matrix, noise_level=0.2, noise_variant=\"uniform\", calibration_variant=\"linear\"\n",
    ")\n",
    "\n",
    "print(noisy_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restoring the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_matrix(\n",
    "    arities,\n",
    "    var_number,\n",
    "    noisy_matrix,\n",
    "    method=\"kmst_prim_incor\",\n",
    "    eps=0.0001,\n",
    "    max_cmplx=-1,\n",
    "    prize_coef=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Experimental setup:__\n",
    "    - 200 arities (from 5 to 50)\n",
    "    - Generate 100 adjacency matrices for each\n",
    "    - Noise and restore several (10) times\n",
    "    - Adjustable parameters: Noise value and type, number of variables, arity, complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small arities, main algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = [\n",
    "    \"greedy_dfs\",\n",
    "    \"greedy_bfs\",\n",
    "    \"prim_fast\",\n",
    "    \"kmst_pure\",\n",
    "    \"kmst_dfs\",\n",
    "    \"kmst_bfs\",\n",
    "    \"kmst_prim\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Warning: this cell takes around 15 minutes for 50 repeats to execute\n",
    "\n",
    "repeats = 2\n",
    "\n",
    "recovered_total = []\n",
    "for alg in algs:\n",
    "    np.random.seed(421)\n",
    "    random.seed(a=472443)\n",
    "    recovered_total_per_alg = do_exp_multiple(repeats,\n",
    "                                              1, (5, 20), [alg], 20, 5, np.linspace(0.0, 1.0, 51),\n",
    "                                              'uniform', 'linear', 1, 5, -1, 0.2, 0.5)\n",
    "    recovered_total.append(recovered_total_per_alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recovered_total[0].shape)\n",
    "new_recovered_total_array = np.zeros(\n",
    "    (recovered_total[0].shape[0], len(algs), recovered_total[0].shape[2])\n",
    ")\n",
    "for i, rec in enumerate(recovered_total):\n",
    "    new_recovered_total_array[:, i : i + 1, :] = rec.copy()\n",
    "print(new_recovered_total_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveas = \"main_algs_full_alpha006_maxarity_5_20.eps\"\n",
    "make_plot_multiple(\n",
    "    algs,\n",
    "    new_recovered_total_array,\n",
    "    repeats,\n",
    "    0.06,\n",
    "    0.0,\n",
    "    np.linspace(0.0, 1.0, 51),\n",
    "    saveas,\n",
    "    (14, 7),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveas = \"main_algs_full_alpha000_maxarity_5_20.eps\"\n",
    "make_plot_multiple(\n",
    "    algs,\n",
    "    new_recovered_total_array,\n",
    "    repeats,\n",
    "    0.00,\n",
    "    0.0,\n",
    "    np.linspace(0.0, 1.0, 51),\n",
    "    saveas,\n",
    "    (14, 7),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveas = \"main_algs_local_alpha000_maxarity_5_20.eps\"\n",
    "make_plot_multiple(\n",
    "    algs,\n",
    "    new_recovered_total_array[:, :, 24:35],\n",
    "    repeats,\n",
    "    0.0,\n",
    "    0.0,\n",
    "    np.linspace(0.48, 0.68, 11),\n",
    "    saveas,\n",
    "    (5, 7),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small arities, basic algorithms enchanced with proposed heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = [\n",
    "    \"greedy_dfs\",\n",
    "    \"greedy_bfs\",\n",
    "    \"prim_fast\",\n",
    "    \"kmst_pure_incor\",\n",
    "    \"kmst_dfs_incor\",\n",
    "    \"kmst_bfs_incor\",\n",
    "    \"kmst_prim_incor\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Warning: this cell takes around 15 minutes for 50 repeats to execute\n",
    "\n",
    "repeats = 2\n",
    "\n",
    "recovered_total_incor = []\n",
    "for alg in algs:\n",
    "    np.random.seed(421)\n",
    "    random.seed(a=472443)\n",
    "    recovered_total_per_alg = do_exp_multiple(repeats,\n",
    "                                              1, (5, 20), [alg], 20, 5, np.linspace(0.0, 1.0, 51),\n",
    "                                              'uniform', 'linear', 1, 5, -1, 0.2, 0.5)\n",
    "    recovered_total_incor.append(recovered_total_per_alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recovered_total_incor[0].shape)\n",
    "new_recovered_total_incor_array = np.zeros(\n",
    "    (recovered_total_incor[0].shape[0], len(algs), recovered_total_incor[0].shape[2])\n",
    ")\n",
    "for i, rec in enumerate(recovered_total_incor):\n",
    "    new_recovered_total_incor_array[:, i : i + 1, :] = rec.copy()\n",
    "print(new_recovered_total_incor_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveas = \"incor_algs_full_alpha006_maxarity_5_20.eps\"\n",
    "make_plot_multiple(\n",
    "    algs,\n",
    "    new_recovered_total_incor_array,\n",
    "    repeats,\n",
    "    0.06,\n",
    "    0.0,\n",
    "    np.linspace(0.0, 1.0, 51),\n",
    "    saveas,\n",
    "    (14, 7),\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveas = \"incor_algs_full_alpha000_maxarity_5_20.eps\"\n",
    "make_plot_multiple(\n",
    "    algs,\n",
    "    new_recovered_total_incor_array,\n",
    "    repeats,\n",
    "    0.00,\n",
    "    0.0,\n",
    "    np.linspace(0.0, 1.0, 51),\n",
    "    saveas,\n",
    "    (14, 7),\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveas = \"incor_algs_local_alpha000_maxarity_5_20.eps\"\n",
    "make_plot_multiple(\n",
    "    algs,\n",
    "    new_recovered_total_incor_array[:, :, 24:35],\n",
    "    repeats,\n",
    "    0.0,\n",
    "    0.0,\n",
    "    np.linspace(0.48, 0.68, 11),\n",
    "    saveas,\n",
    "    (5, 7),\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 research env",
   "language": "python",
   "name": "py3_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
